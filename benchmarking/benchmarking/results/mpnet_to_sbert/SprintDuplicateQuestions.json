{
  "dataset_revision": "d66bd1f72af766a5cc4b0ca5e00c162f89e8cc46",
  "mteb_dataset_name": "SprintDuplicateQuestions",
  "mteb_version": "1.0.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.9955742574257426,
      "accuracy_threshold": 0.7435069680213928,
      "ap": 0.8171114652535971,
      "f1": 0.763874873864783,
      "f1_threshold": 0.6955229043960571,
      "precision": 0.7708757637474541,
      "recall": 0.757
    },
    "dot": {
      "accuracy": 0.9902079207920792,
      "accuracy_threshold": 453.6845703125,
      "ap": 0.22306913586810173,
      "f1": 0.2934734997809899,
      "f1_threshold": 158.74411010742188,
      "precision": 0.26110678098207324,
      "recall": 0.335
    },
    "euclidean": {
      "accuracy": 0.9946435643564356,
      "accuracy_threshold": 7.936818599700928,
      "ap": 0.6742787558377212,
      "f1": 0.6784897025171625,
      "f1_threshold": 8.448951721191406,
      "precision": 0.7927807486631016,
      "recall": 0.593
    },
    "evaluation_time": 12.97,
    "manhattan": {
      "accuracy": 0.9945940594059406,
      "accuracy_threshold": 121.42911529541016,
      "ap": 0.6751080290803901,
      "f1": 0.6812176909821941,
      "f1_threshold": 131.24050903320312,
      "precision": 0.8002699055330634,
      "recall": 0.593
    },
    "max": {
      "accuracy": 0.9955742574257426,
      "ap": 0.8171114652535971,
      "f1": 0.763874873864783
    }
  },
  "validation": {
    "cos_sim": {
      "accuracy": 0.9955643564356436,
      "accuracy_threshold": 0.722447395324707,
      "ap": 0.8287218354388705,
      "f1": 0.7668867445403759,
      "f1_threshold": 0.6809645295143127,
      "precision": 0.7791537667698658,
      "recall": 0.755
    },
    "dot": {
      "accuracy": 0.9903267326732673,
      "accuracy_threshold": 377.6144714355469,
      "ap": 0.24778002930690443,
      "f1": 0.3103939250118652,
      "f1_threshold": 161.02139282226562,
      "precision": 0.2953929539295393,
      "recall": 0.327
    },
    "euclidean": {
      "accuracy": 0.994049504950495,
      "accuracy_threshold": 8.136926651000977,
      "ap": 0.6499442865783388,
      "f1": 0.632112676056338,
      "f1_threshold": 8.858064651489258,
      "precision": 0.7238709677419355,
      "recall": 0.561
    },
    "evaluation_time": 15.31,
    "manhattan": {
      "accuracy": 0.994039603960396,
      "accuracy_threshold": 127.35018157958984,
      "ap": 0.6506922112468009,
      "f1": 0.6329411764705883,
      "f1_threshold": 133.991455078125,
      "precision": 0.7685714285714286,
      "recall": 0.538
    },
    "max": {
      "accuracy": 0.9955643564356436,
      "ap": 0.8287218354388705,
      "f1": 0.7668867445403759
    }
  }
}